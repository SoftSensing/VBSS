{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "# load data\n",
    "\n",
    "# relative path to npz files\n",
    "path = 'Measurements/manual single top deformed at 20Hz'\n",
    "file_name = 'output_batch_%d.npz'\n",
    "\n",
    "def load_file(path, batch_id):\n",
    "    \"\"\"\n",
    "    Loads in the memory a specific batch located in the given path.\n",
    "\n",
    "    Returns a numpy NpzFile object with the image frames np array named\n",
    "    as \"frames\" and the force measurements named as \"frames\".\n",
    "    \"\"\"\n",
    "    combined_path = os.path.join(path,file_name %i)\n",
    "    data = np.load(combined_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(input_channels, 9, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 4, stride = 4)\n",
    "        self.conv2 = nn.Conv2d(9, 18, kernel_size = 5, stride = 1, padding = 2)\n",
    "        \n",
    "        # RNN\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.rnn = nn.RNN(18 * 16 * 30, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool(nn.ELU()(self.conv1(x)))\n",
    "        x = self.pool(nn.ELU()(self.conv2(x)))\n",
    "        \n",
    "        # Reshape for RNN\n",
    "        # x = torch.reshape(x, (100, 10, 18 * 16 * 30))\n",
    "        x = torch.reshape(x, (10, 10, 18 * 16 * 30))  # Reshape to (batch_size, seq_len, input_size)\n",
    "        print(\"Size of x:\", x.size())  # Print size of x\n",
    "        \n",
    "        # RNN\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        #print(\"Size of h0:\", h0.size())  # Print size of h0 - Debugging - Obsolete\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Output layer\n",
    "        out = self.fc(out) \n",
    "        # out = torch.reshape(out, (1000, 1))\n",
    "        out = torch.reshape(out, (100, 1)) # go back to compare to labels\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RNN\n",
    "input_channels = 3  # RGB channels\n",
    "hidden_dim = 200  # hidden layer dimension\n",
    "layer_dim = 2     # number of hidden layers\n",
    "output_dim = 1   # output dimension\n",
    "\n",
    "model = RNNModel(input_channels, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Define your loss function\n",
    "error = nn.MSELoss()\n",
    "\n",
    "# Define your optimizer\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 1  Loss: 25.964763641357422\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 2  Loss: 333.91070556640625\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 3  Loss: 43.58935546875\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 4  Loss: 35.99770736694336\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 5  Loss: 132.87515258789062\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 6  Loss: 99.73667907714844\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 7  Loss: 32.80963134765625\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 8  Loss: 4.310567855834961\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 9  Loss: 28.79064178466797\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 10  Loss: 51.25714874267578\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 11  Loss: 42.23223114013672\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 12  Loss: 17.619287490844727\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 13  Loss: 2.630267381668091\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 14  Loss: 9.768749237060547\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 15  Loss: 20.378616333007812\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 16  Loss: 21.219022750854492\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 17  Loss: 15.51965045928955\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 18  Loss: 5.318990707397461\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 19  Loss: 3.509101629257202\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 20  Loss: 8.225696563720703\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 21  Loss: 13.164437294006348\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 22  Loss: 8.140320777893066\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 23  Loss: 7.376404285430908\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 24  Loss: 2.9513063430786133\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 25  Loss: 1.7213718891143799\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 26  Loss: 4.294377326965332\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 27  Loss: 6.9579362869262695\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 28  Loss: 4.6931681632995605\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 29  Loss: 2.934767961502075\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 30  Loss: 1.8695160150527954\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 31  Loss: 2.0913825035095215\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 32  Loss: 4.1838154792785645\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 33  Loss: 4.0309858322143555\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 34  Loss: 2.930509567260742\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 35  Loss: 1.9484519958496094\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 36  Loss: 2.2301154136657715\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 37  Loss: 3.0099925994873047\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 38  Loss: 3.068563461303711\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 39  Loss: 2.4152519702911377\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 40  Loss: 2.392714500427246\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 41  Loss: 2.56831431388855\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 42  Loss: 1.143338680267334\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 43  Loss: 2.0863699913024902\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 44  Loss: 1.944810390472412\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 45  Loss: 0.8857980370521545\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 46  Loss: 0.7483943104743958\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 47  Loss: 0.8977577686309814\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 48  Loss: 1.4717963933944702\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 49  Loss: 1.483856201171875\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 50  Loss: 1.5689630508422852\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 51  Loss: 1.2589300870895386\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 52  Loss: 1.6116976737976074\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 53  Loss: 1.3731178045272827\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 54  Loss: 1.5147818326950073\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 55  Loss: 1.5679726600646973\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 56  Loss: 1.8031127452850342\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 57  Loss: 1.4771839380264282\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 58  Loss: 1.170130968093872\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 59  Loss: 1.72633695602417\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 60  Loss: 1.9249005317687988\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 61  Loss: 2.2286019325256348\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 62  Loss: 0.936835527420044\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 63  Loss: 1.112025260925293\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 64  Loss: 1.0267322063446045\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 65  Loss: 0.7913147211074829\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 66  Loss: 0.6285079717636108\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 67  Loss: 0.5151941180229187\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 68  Loss: 1.3159804344177246\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 69  Loss: 1.2018823623657227\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 70  Loss: 1.313715934753418\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 71  Loss: 1.046120047569275\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 72  Loss: 1.323858380317688\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 73  Loss: 1.0758657455444336\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 74  Loss: 1.2172318696975708\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 75  Loss: 1.293829321861267\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 76  Loss: 1.5142172574996948\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 77  Loss: 1.1788727045059204\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 78  Loss: 0.8271551728248596\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 79  Loss: 1.544527530670166\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 80  Loss: 1.5616024732589722\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 81  Loss: 1.813496708869934\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 82  Loss: 0.9264624118804932\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 83  Loss: 0.8421687483787537\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 84  Loss: 0.765089213848114\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 85  Loss: 0.5578842759132385\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 86  Loss: 0.46044114232063293\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 87  Loss: 0.34841156005859375\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 88  Loss: 1.003688931465149\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 89  Loss: 0.8601299524307251\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 90  Loss: 1.060461401939392\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 91  Loss: 0.8641414642333984\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 92  Loss: 1.013565182685852\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 93  Loss: 0.8209840655326843\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 94  Loss: 0.9493595957756042\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 95  Loss: 0.9815319776535034\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 96  Loss: 1.1718934774398804\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 97  Loss: 0.9820965528488159\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 98  Loss: 0.6610204577445984\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 99  Loss: 1.2484501600265503\n",
      "Size of x: torch.Size([10, 10, 8640])\n",
      "Iteration: 100  Loss: 1.2839081287384033\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "file_size = 1000 # one file contains 1000 samples\n",
    "num_epochs = 5\n",
    "files_num = 2 # how many files to load\n",
    "seq_dim = 100\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "batch_size = 100 # should be something that leaves zero reminder when it divides the file_size\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(files_num):\n",
    "        data = load_file(path, i)\n",
    "        \n",
    "        for i in range(int(file_size/batch_size)):\n",
    "            images = torch.from_numpy(data['frames'][i*batch_size:(i+1)*batch_size,:,:,:]).float()\n",
    "            labels = torch.from_numpy(data['forces'][i*batch_size:(i+1)*batch_size,2]).float()        \n",
    "            # print(images.shape)  # Add this line to check the shape of images - Debugging purposes\n",
    "            images = images.permute(0, 3, 1, 2)\n",
    "                \n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward propagation\n",
    "            outputs = model(images)\n",
    "            outputs = torch.squeeze(outputs)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = error(outputs, labels)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            count += 1\n",
    "                \n",
    "            # Store loss and iteration\n",
    "            loss_list.append(loss.data) #* (forces_z_std^2)\n",
    "            # Print Loss\n",
    "            if count % 1 == 0: # for now print for every iteration\n",
    "                print('Iteration: {}  Loss: {}'.format(count, loss.data.item())) # * (forces_z_std^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(25.9648), tensor(333.9107), tensor(43.5894), tensor(35.9977), tensor(132.8752), tensor(99.7367), tensor(32.8096), tensor(4.3106), tensor(28.7906), tensor(51.2571), tensor(42.2322), tensor(17.6193), tensor(2.6303), tensor(9.7687), tensor(20.3786), tensor(21.2190), tensor(15.5197), tensor(5.3190), tensor(3.5091), tensor(8.2257), tensor(13.1644), tensor(8.1403), tensor(7.3764), tensor(2.9513), tensor(1.7214), tensor(4.2944), tensor(6.9579), tensor(4.6932), tensor(2.9348), tensor(1.8695), tensor(2.0914), tensor(4.1838), tensor(4.0310), tensor(2.9305), tensor(1.9485), tensor(2.2301), tensor(3.0100), tensor(3.0686), tensor(2.4153), tensor(2.3927), tensor(2.5683), tensor(1.1433), tensor(2.0864), tensor(1.9448), tensor(0.8858), tensor(0.7484), tensor(0.8978), tensor(1.4718), tensor(1.4839), tensor(1.5690), tensor(1.2589), tensor(1.6117), tensor(1.3731), tensor(1.5148), tensor(1.5680), tensor(1.8031), tensor(1.4772), tensor(1.1701), tensor(1.7263), tensor(1.9249), tensor(2.2286), tensor(0.9368), tensor(1.1120), tensor(1.0267), tensor(0.7913), tensor(0.6285), tensor(0.5152), tensor(1.3160), tensor(1.2019), tensor(1.3137), tensor(1.0461), tensor(1.3239), tensor(1.0759), tensor(1.2172), tensor(1.2938), tensor(1.5142), tensor(1.1789), tensor(0.8272), tensor(1.5445), tensor(1.5616), tensor(1.8135), tensor(0.9265), tensor(0.8422), tensor(0.7651), tensor(0.5579), tensor(0.4604), tensor(0.3484), tensor(1.0037), tensor(0.8601), tensor(1.0605), tensor(0.8641), tensor(1.0136), tensor(0.8210), tensor(0.9494), tensor(0.9815), tensor(1.1719), tensor(0.9821), tensor(0.6610), tensor(1.2485), tensor(1.2839)]\n",
      "0.9988469\n"
     ]
    }
   ],
   "source": [
    "print(loss_list)\n",
    "print(np.sqrt(np.mean(loss_list[-10:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1077, -1.0038, -0.7995, -1.4391, -0.8869, -1.0202, -0.5590, -0.3168,\n",
      "        -0.5819, -0.3737, -0.7441, -0.3708, -0.4237, -0.7871, -0.4383, -0.2764,\n",
      "        -0.3442, -0.2389, -0.3068, -0.0540, -0.4404, -0.5306, -0.4157, -0.7802,\n",
      "        -0.4667, -0.2456, -0.2674, -0.1639, -0.2056, -0.0587, -0.8580, -0.9465,\n",
      "        -1.1103, -2.0071, -1.8482, -2.4549, -2.5280, -1.6560, -2.4050, -2.3047,\n",
      "        -2.1320, -2.1171, -2.5134, -2.7933, -2.7854, -2.1296, -2.1062, -1.0555,\n",
      "        -0.9705, -0.7812, -1.1566, -0.8603, -0.8723, -1.1510, -0.9536, -0.6834,\n",
      "        -0.4529, -0.3104, -0.6955, -0.5685, -0.8926, -0.5106, -0.4582, -1.0635,\n",
      "        -0.3563, -0.2808, -0.3622, -0.2676, -0.2375, -0.0143, -0.6605, -0.5229,\n",
      "        -0.5316, -1.1870, -1.2191, -1.2330, -1.8680, -2.4337, -1.9806, -2.3055,\n",
      "        -2.2983, -2.4070, -2.4080, -2.8696, -2.7027, -2.9402, -2.1496, -2.0185,\n",
      "        -0.8987, -1.0645, -1.2537, -1.0703, -0.8970, -1.3609, -1.0010, -1.0393,\n",
      "        -0.6597, -0.4886, -0.5171, -0.5415], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs) # Small sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9837, -0.1637, -0.1279, -0.1309, -0.1346, -0.1297, -0.1344, -0.1294,\n",
      "        -0.1343, -0.1282, -0.1322, -0.1240, -0.1298, -0.1313, -0.1317, -0.1270,\n",
      "        -0.1292, -0.1361, -0.1341, -0.1336, -0.1390, -0.1233, -0.1278, -0.1282,\n",
      "        -0.1346, -0.1320, -0.1334, -0.1283, -0.1324, -0.3513, -1.0552, -1.5855,\n",
      "        -2.5075, -2.8629, -3.2809, -3.5987, -4.0110, -4.4015, -4.5454, -4.9288,\n",
      "        -5.1063, -5.1722, -4.9448, -4.5689, -3.3009, -1.5864, -0.2401, -0.1187,\n",
      "        -0.1239, -0.1288, -0.1313, -0.1257, -0.1342, -0.1297, -0.1307, -0.1230,\n",
      "        -0.1293, -0.1233, -0.1307, -0.1248, -0.1389, -0.1326, -0.1363, -0.1292,\n",
      "        -0.1340, -0.1309, -0.1326, -0.1288, -0.1315, -0.1237, -0.1371, -0.3839,\n",
      "        -0.8983, -1.3171, -2.2785, -2.7973, -3.4132, -3.8083, -4.2586, -4.6140,\n",
      "        -4.6368, -4.7419, -4.7785, -4.7576, -4.3578, -3.5074, -1.8832, -0.4341,\n",
      "        -0.1187, -0.1313, -0.1282, -0.1306, -0.1325, -0.1369, -0.1345, -0.1265,\n",
      "        -0.1310, -0.1315, -0.1313, -0.1277])\n"
     ]
    }
   ],
   "source": [
    "print(labels.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress Summary: 2 Conv&Pool layers, RNN with 2 hidden states of 200 size, 10 sequence length, 5 epochs: 1.042 RMSE. Best performance by a small margin, albeit on training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CNN SUBNET\n",
    "This notebook shows how to use a CNN as a subnet in the encoder of a subspace system identification model. The CNN is used to process image inputs. The model is trained on a dataset of images and forces. The model is then tested on a test dataset to predict the forces. The model is evaluated using the NRMS metric."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing the required libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9b7f11-681b-4d7b-b5c9-1233c5eb78c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:52:44.480448Z",
     "iopub.status.busy": "2024-06-10T15:52:44.479612Z",
     "iopub.status.idle": "2024-06-10T15:52:54.176193Z",
     "shell.execute_reply": "2024-06-10T15:52:54.175468Z",
     "shell.execute_reply.started": "2024-06-10T15:52:44.480415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/GerbenBeintema/deepSI@master\n",
      "  Cloning https://github.com/GerbenBeintema/deepSI (to revision master) to /tmp/pip-req-build-sfh3c_46\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/GerbenBeintema/deepSI /tmp/pip-req-build-sfh3c_46\n",
      "  Resolved https://github.com/GerbenBeintema/deepSI to commit 28c96c174fa2e1c83aeb26091d67785d468a4bee\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (1.23.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (3.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (1.9.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (4.64.1)\n",
      "Requirement already satisfied: progressbar in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (2.5)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (1.12.1+cu116)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (1.1.2)\n",
      "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (0.26.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (4.6.0.66)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (2.28.2)\n",
      "Requirement already satisfied: rarfile in /usr/local/lib/python3.9/dist-packages (from deepSI==0.3.22) (4.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym->deepSI==0.3.22) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym->deepSI==0.3.22) (2.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym->deepSI==0.3.22) (6.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepSI==0.3.22) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepSI==0.3.22) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepSI==0.3.22) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepSI==0.3.22) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepSI==0.3.22) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepSI==0.3.22) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepSI==0.3.22) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->deepSI==0.3.22) (23.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->deepSI==0.3.22) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->deepSI==0.3.22) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->deepSI==0.3.22) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->deepSI==0.3.22) (2019.11.28)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->deepSI==0.3.22) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->deepSI==0.3.22) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->deepSI==0.3.22) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym->deepSI==0.3.22) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->deepSI==0.3.22) (1.14.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/GerbenBeintema/deepSI@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2460d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:52:54.177688Z",
     "iopub.status.busy": "2024-06-10T15:52:54.177478Z",
     "iopub.status.idle": "2024-06-10T15:52:57.467586Z",
     "shell.execute_reply": "2024-06-10T15:52:57.466836Z",
     "shell.execute_reply.started": "2024-06-10T15:52:54.177670Z"
    }
   },
   "outputs": [],
   "source": [
    "import deepSI\n",
    "from deepSI import System_data, System_data_list\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "from torch import optim, nn\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "linewidth = 3.320\n",
    "reducesize = 0.95\n",
    "fig_fontsize = (10*19/28)*reducesize\n",
    "plt.rcParams.update({'font.size': fig_fontsize})\n",
    "dpi = 200\n",
    "pad = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download the FFmpeg binaries\n",
    "The FFmpeg binaries are required to extract the frames from the video files. The following code downloads the FFmpeg binaries and extracts them to a specified directory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c171a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:52:57.471448Z",
     "iopub.status.busy": "2024-06-10T15:52:57.471125Z",
     "iopub.status.idle": "2024-06-10T15:53:05.676152Z",
     "shell.execute_reply": "2024-06-10T15:53:05.675396Z",
     "shell.execute_reply.started": "2024-06-10T15:52:57.471427Z"
    }
   },
   "outputs": [],
   "source": [
    "archive_path = 'ffmpeg-master-latest-linux64-gpl.tar.xz'\n",
    "output_dir = 'ffmpeg/'  # You can use an existing or new directory\n",
    "\n",
    "# Extract the archive\n",
    "!tar -xf {archive_path} -C {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef1b15b-0623-459f-8782-3999e840e1c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:05.677192Z",
     "iopub.status.busy": "2024-06-10T15:53:05.677004Z",
     "iopub.status.idle": "2024-06-10T15:53:05.681077Z",
     "shell.execute_reply": "2024-06-10T15:53:05.680656Z",
     "shell.execute_reply.started": "2024-06-10T15:53:05.677172Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Example directory containing the FFmpeg binaries\n",
    "ffmpeg_dir = 'ffmpeg/ffmpeg-master-latest-linux64-gpl/bin'\n",
    "\n",
    "# Add the FFmpeg directory to the PATH environment variable\n",
    "os.environ['PATH'] = ffmpeg_dir + os.pathsep + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation\n",
    "The data is prepared by extracting the frames from the video files. The frames are then stored in a NumPy array. The forces are stored in a separate NumPy array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d55f49-3bdd-4007-9549-81b82191984f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:05.683218Z",
     "iopub.status.busy": "2024-06-10T15:53:05.683042Z",
     "iopub.status.idle": "2024-06-10T15:53:38.437975Z",
     "shell.execute_reply": "2024-06-10T15:53:38.437328Z",
     "shell.execute_reply.started": "2024-06-10T15:53:05.683202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5e4e9a6baf45738975edff2ed45c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resizing frames:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the npz file\n",
    "adi = 12\n",
    "systemsdir = 'systems_force/'\n",
    "filen = 'combined_output_20_3.npz'\n",
    "data = np.load(filen, allow_pickle=True)\n",
    "\n",
    "# Arrays 'frames' and 'forces' within your npz file\n",
    "frames = data['frames']\n",
    "forces = data['forces']\n",
    "\n",
    "# Determine the size of each set\n",
    "total_size = len(frames)\n",
    "train_size = int(total_size * 0.6)  # 60% of the data for training\n",
    "val_size = int(total_size * 0.20)  # 20% of the data for validation\n",
    "test_size = total_size - train_size - val_size  # Remaining 20% for testing\n",
    "\n",
    "# Function to resize and reshape frames with progress bar\n",
    "def resize_and_reshape_frames(frames, batch_size, new_height, new_width):\n",
    "    num_frames = frames.shape[0]\n",
    "    resized_and_reshaped_frames = np.zeros((num_frames, frames.shape[3], new_height, new_width), dtype=np.uint8)\n",
    "    for start in tqdm(range(0, num_frames, batch_size), desc=\"Resizing frames\"):\n",
    "        end = start + batch_size\n",
    "        batch_frames = frames[start:end]\n",
    "        for i in range(batch_frames.shape[0]):\n",
    "            resized_frame = cv2.resize(batch_frames[i], (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "            resized_and_reshaped_frames[start + i] = resized_frame.transpose(2, 0, 1)\n",
    "    return resized_and_reshaped_frames\n",
    "\n",
    "# Resize and reshape parameters\n",
    "new_height = frames.shape[1] // 2\n",
    "new_width = frames.shape[2] // 2\n",
    "batch_size = 30\n",
    "\n",
    "# Resize and reshape all frames\n",
    "frames_resized_reshaped = resize_and_reshape_frames(frames, batch_size, new_height, new_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split the data\n",
    "The data is split into training, validation, and testing sets. The training set is used to train the model, the validation set is used to validate the model during training, and the testing set is used to evaluate the model after training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa9cd84-1f34-4f30-aff7-9f3274baa1c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.439031Z",
     "iopub.status.busy": "2024-06-10T15:53:38.438852Z",
     "iopub.status.idle": "2024-06-10T15:53:38.471900Z",
     "shell.execute_reply": "2024-06-10T15:53:38.471239Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.439015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "del frames\n",
    "frames_train = frames_resized_reshaped[:train_size]\n",
    "frames_val = frames_resized_reshaped[train_size:train_size + val_size]\n",
    "frames_test = frames_resized_reshaped[train_size + val_size:]\n",
    "n_channels, height, width = frames_train.shape[1], frames_train.shape[2], frames_train.shape[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9214f7bd-3948-4144-885c-6b6c268a1e03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.472863Z",
     "iopub.status.busy": "2024-06-10T15:53:38.472681Z",
     "iopub.status.idle": "2024-06-10T15:53:38.476421Z",
     "shell.execute_reply": "2024-06-10T15:53:38.475918Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.472863Z"
    }
   },
   "outputs": [],
   "source": [
    "forces_train = forces[:train_size, 2]\n",
    "forces_val = forces[train_size:train_size + val_size, 2]\n",
    "forces_test = forces[train_size + val_size:, 2]\n",
    "del forces\n",
    "# Initialize the SS_encoder_CNN_video system\n",
    "#sys_vbss = deepSI.fit_systems.SS_encoder_CNN_video(na=adi, nb=adi)\n",
    "n_channels, height, width = frames_train.shape[1], frames_train.shape[2], frames_train.shape[3]\n",
    "#sys_vbss.init_nets(nu=1, ny=(n_channels, height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f4cce54-84b4-4888-af09-736477aba682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.477238Z",
     "iopub.status.busy": "2024-06-10T15:53:38.477080Z",
     "iopub.status.idle": "2024-06-10T15:53:38.480869Z",
     "shell.execute_reply": "2024-06-10T15:53:38.480297Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.477224Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create System_data instances with resized and reshaped frames\n",
    "system_data = System_data(y=forces_train, u=frames_train)\n",
    "system_data_val = System_data(y=forces_val, u=frames_val)\n",
    "system_data_test = System_data(y=forces_test, u=frames_test)\n",
    "del forces_train, frames_train, forces_val, frames_val, forces_test, frames_test"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the CNN encoder\n",
    "The CNN encoder is defined as a subclass of the `nn.Module` class in PyTorch. The CNN encoder takes the past input and output data as input and returns the initial state of the system."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3913141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.481640Z",
     "iopub.status.busy": "2024-06-10T15:53:38.481481Z",
     "iopub.status.idle": "2024-06-10T15:53:38.489791Z",
     "shell.execute_reply": "2024-06-10T15:53:38.489138Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.481626Z"
    },
    "ExecuteTime": {
     "end_time": "2024-06-10T17:24:11.302458500Z",
     "start_time": "2024-06-10T17:24:04.680436900Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdeepSI\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtorch_nets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CNN_encoder\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#Psi(upast, ypast) where upast is an image and ypast an vector\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#nb, nu, na, ny, nx\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCNN_encoder_image_input\u001B[39;00m(\u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, nb, nu, na, ny, nx, n_nodes_per_layer\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, n_hidden_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, activation\u001B[38;5;241m=\u001B[39mnn\u001B[38;5;241m.\u001B[39mTanh, features_ups_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.33\u001B[39m):\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;28msuper\u001B[39m(CNN_encoder_image_input, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "from deepSI.utils.torch_nets import CNN_encoder\n",
    "\n",
    "\n",
    "#Psi(upast, ypast) where upast is an image and ypast an vector\n",
    "#nb, nu, na, ny, nx\n",
    "class CNN_encoder_image_input(nn.Module):\n",
    "    def __init__(self, nb, nu, na, ny, nx, n_nodes_per_layer=64, n_hidden_layers=2, activation=nn.Tanh, features_ups_factor=1.33):\n",
    "        super(CNN_encoder_image_input, self).__init__()\n",
    "        self.net = CNN_encoder(na, ny, nb, nu, nx, \\\n",
    "                               n_nodes_per_layer=n_nodes_per_layer, \\\n",
    "                               n_hidden_layers=n_hidden_layers, \\\n",
    "                                activation=activation, \\\n",
    "                                features_ups_factor=features_ups_factor)\n",
    "\n",
    "    def forward(self, upast, ypast):\n",
    "        return self.net(ypast, upast)\n",
    "\n",
    "#nx, nu\n",
    "class CNN_encoder_f_image(nn.Module):\n",
    "    def __init__(self, nx, nu, n_nodes_per_layer=64, n_hidden_layers=2, activation=nn.Tanh, features_ups_factor=1.33):\n",
    "        super(CNN_encoder_f_image, self).__init__()\n",
    "        self.net = CNN_encoder(1, nx, 1, nu, nx, \n",
    "                               n_nodes_per_layer=n_nodes_per_layer, \n",
    "                               n_hidden_layers=n_hidden_layers, \n",
    "                               activation=activation, \n",
    "                               features_ups_factor=features_ups_factor)\n",
    "\n",
    "    def forward(self, x, u):\n",
    "        # Ensure x and u are tensors\n",
    "        if isinstance(x, list) or isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        if isinstance(u, list) or isinstance(u, np.ndarray):\n",
    "            u = torch.tensor(u, dtype=torch.float32)\n",
    "        \n",
    "        # Ensure the correct shape for x and u\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        if len(u.shape) == 1:\n",
    "            u = u.unsqueeze(0)\n",
    "        \n",
    "        # x.shape = (Nbatch, nx)\n",
    "        # u.shape = (Nbatch, C, H, W)\n",
    "        return self.net(x[:, None], u[:, None])\n",
    "\n",
    "    \n",
    "#nx, ny, nu=-1\n",
    "class CNN_encoder_h_image(nn.Module):\n",
    "    def __init__(self, nx, ny, nu, n_nodes_per_layer=64, n_hidden_layers=2, activation=nn.Tanh, features_ups_factor=1.33):\n",
    "        super(CNN_encoder_h_image, self).__init__()\n",
    "        self.net = CNN_encoder(1, nx, 1, nu, ny, \\\n",
    "                               n_nodes_per_layer=n_nodes_per_layer, \\\n",
    "                               n_hidden_layers=n_hidden_layers, \\\n",
    "                                activation=activation, \\\n",
    "                                features_ups_factor=features_ups_factor)\n",
    "\n",
    "    def forward(self, x, u):\n",
    "        #x.shape = (Nbatch, nx)\n",
    "        #u.shape = (Nbatch, C, H, W)\n",
    "\n",
    "        #self.net \n",
    "        # x -> upast = (Nbatch, nb, nu)\n",
    "        # u -> ypast = (Nbatch, na, C, H, W)\n",
    "        return self.net(x[:,None], u[:,None])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define the SS_encoder_CNN_video system\n",
    "The `SS_encoder_CNN_video` system is defined as a subclass of the `SS_encoder_general` class in deepSI. The `SS_encoder_CNN_video` system uses the CNN encoder defined above to process image inputs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4c63561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.490617Z",
     "iopub.status.busy": "2024-06-10T15:53:38.490426Z",
     "iopub.status.idle": "2024-06-10T15:53:38.767192Z",
     "shell.execute_reply": "2024-06-10T15:53:38.766496Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.490600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System_data of length: 7200 nu=(3, 135, 240) ny=None normed=False dt=None\n"
     ]
    }
   ],
   "source": [
    "# from deepSI.utils import CNN_chained_upscales, CNN_encoder\n",
    "from deepSI.fit_systems import *\n",
    "\n",
    "class SS_encoder_CNN_video_input(SS_encoder_general):\n",
    "    \"\"\"The subspace encoder convolutonal neural network with image inputs\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The subspace encoder\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, nx=10, na=20, nb=20, feedthrough=True, e_net=CNN_encoder_image_input, \\\n",
    "                 f_net=CNN_encoder_f_image, h_net=CNN_encoder_h_image, \\\n",
    "                                            e_net_kwargs={}, f_net_kwargs={}, h_net_kwargs={}):\n",
    "        super(SS_encoder_CNN_video_input, self).__init__(nx=nx,na=na,nb=nb, feedthrough=feedthrough, \\\n",
    "            e_net=e_net,               f_net=f_net,                h_net=h_net, \\\n",
    "            e_net_kwargs=e_net_kwargs, f_net_kwargs=f_net_kwargs,  h_net_kwargs=h_net_kwargs)\n",
    "\n",
    "model = SS_encoder_CNN_video_input(nx=5, na=12, nb=12)\n",
    "\n",
    "# nu = (3,25,30)\n",
    "# ny = 1\n",
    "# N = 200\n",
    "# u_seq = np.random.randn(N,*nu)\n",
    "# y_seq = np.random.randn(N, ny)\n",
    "#sys_data = System_data(u_seq, y_seq)\n",
    "\n",
    "print(system_data)\n",
    "model.init_model(nu=(3,135,240), ny=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Patching the methods\n",
    "The `SS_encoder_general` class is patched to include the `apply_experiment` and `loss` methods. The `apply_experiment` method is used to apply the system to the data, while the `loss` method is used to calculate the loss during training. The patched methods are defined below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b6180a-d004-44de-abcc-ff1588cfd577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.768219Z",
     "iopub.status.busy": "2024-06-10T15:53:38.768039Z",
     "iopub.status.idle": "2024-06-10T15:53:38.771838Z",
     "shell.execute_reply": "2024-06-10T15:53:38.771221Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.768203Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepSI.fit_systems.fit_system import Tictoctimer\n",
    "from deepSI.systems import *\n",
    "import time\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "# Get the System_torch class from deepSI\n",
    "System_torch = deepSI.fit_systems.fit_system.System_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b529650-c3a3-4bfd-96c6-0e6bc71073cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.772991Z",
     "iopub.status.busy": "2024-06-10T15:53:38.772826Z",
     "iopub.status.idle": "2024-06-10T15:53:38.782017Z",
     "shell.execute_reply": "2024-06-10T15:53:38.781320Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.772976Z"
    }
   },
   "outputs": [],
   "source": [
    "def patched_apply_experiment(self, sys_data, save_state=False, init_state=True):\n",
    "    if isinstance(sys_data, (tuple, list, System_data_list)):\n",
    "        return System_data_list([self.apply_experiment(sd, save_state=save_state, init_state=init_state) for sd in sys_data])\n",
    "    \n",
    "    sys_data_norm = self.norm.transform(sys_data)  # Normalize the system data\n",
    "\n",
    "    dt_old = self.dt\n",
    "    if sys_data.dt is not None:\n",
    "        self.dt = sys_data.dt  # Update the system's dt if available\n",
    "\n",
    "    U, Y = sys_data_norm.u, []\n",
    "    if not init_state:\n",
    "        k0 = 0\n",
    "    elif sys_data_norm.y is not None:\n",
    "        k0 = self.init_state(sys_data_norm)\n",
    "        Y.extend(sys_data_norm.y[:k0])\n",
    "    else:\n",
    "        k0, _ = 0, self.reset_state()\n",
    "\n",
    "    if save_state:\n",
    "        X = [self.get_state()] * k0\n",
    "\n",
    "    for u in U[k0:]:\n",
    "        if save_state:\n",
    "            X.append(self.get_state())\n",
    "        Y.append(self.measure_act(u))  # Measure and advance state\n",
    "\n",
    "    if dt_old is not None:\n",
    "        self.dt = dt_old\n",
    "\n",
    "    # Ensure that U, Y, and X are properly shaped\n",
    "    U = np.array(U, dtype=object)\n",
    "    Y = np.array(Y, dtype=object)\n",
    "    X = np.array(X, dtype=object) if save_state else None\n",
    "\n",
    "    return self.norm.inverse_transform(System_data(u=U, y=Y, x=X, normed=True, cheat_n=k0, dt=sys_data.dt))\n",
    "\n",
    "# Define the patched version of the loss method\n",
    "def patched_loss(self, uhist, yhist, ufuture, yfuture, loss_nf_cutoff=None, **Loss_kwargs):\n",
    "    x = self.encoder(uhist, yhist)  # Initialize Nbatch number of states\n",
    "    errors = []\n",
    "    for y, u in zip(torch.transpose(yfuture, 0, 1), torch.transpose(ufuture, 0, 1)):  # Iterate over time\n",
    "        y_pred = self.hn(x, u) if self.feedthrough else self.hn(x)\n",
    "        \n",
    "        # Ensure that y and y_pred have the same shape\n",
    "        if y.dim() != y_pred.dim():\n",
    "            y_pred = y_pred.view(-1) if y.dim() == 1 else y_pred.view(-1, 1)\n",
    "            y = y.view(-1) if y_pred.dim() == 1 else y.view(-1, 1)\n",
    "\n",
    "        error = nn.functional.mse_loss(y, y_pred)\n",
    "        errors.append(error)  # Calculate error after taking n-steps\n",
    "        \n",
    "        if loss_nf_cutoff is not None and error.item() > loss_nf_cutoff:\n",
    "            print(len(errors), end=' ')\n",
    "            break\n",
    "        \n",
    "        x = self.fn(x, u)  # Advance state\n",
    "\n",
    "    return torch.mean(torch.stack(errors))\n",
    "\n",
    "# Monkey patch the methods in the respective classes\n",
    "SS_encoder_general.apply_experiment = patched_apply_experiment  # Replace with the actual class name\n",
    "SS_encoder_general.loss = patched_loss  # Replace with the actual class name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73cca44-58ff-4149-a4e9-4c474664124f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.783459Z",
     "iopub.status.busy": "2024-06-10T15:53:38.783020Z",
     "iopub.status.idle": "2024-06-10T15:53:38.787886Z",
     "shell.execute_reply": "2024-06-10T15:53:38.787332Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.783440Z"
    }
   },
   "outputs": [],
   "source": [
    "def patched_RMS_System_data(self, real, multi_average=True):\n",
    "    y, yhat = real.y[self.cheat_n:], self.y[self.cheat_n:]\n",
    "    error = np.sqrt(np.mean((y - yhat) ** 2, axis=0))\n",
    "    if multi_average:\n",
    "        return np.mean(error)\n",
    "    return error\n",
    "\n",
    "def patched_RMS_System_data_list(self, real, multi_average=True):\n",
    "    rms_values = [sd.RMS(sdo, multi_average=multi_average) for sd, sdo in zip(self.sdl, real.sdl)]\n",
    "    weights = np.array([len(sd) for sd in self.sdl])\n",
    "    return np.sum(weights * rms_values) / np.sum(weights)\n",
    "\n",
    "# Patch the RMS method in System_data\n",
    "System_data.RMS = patched_RMS_System_data\n",
    "\n",
    "# Patch the RMS method in System_data_list\n",
    "System_data_list.RMS = patched_RMS_System_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75bc70a4-6dfd-4242-bb0c-46fd9b0ddbf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.791412Z",
     "iopub.status.busy": "2024-06-10T15:53:38.790848Z",
     "iopub.status.idle": "2024-06-10T15:53:38.795732Z",
     "shell.execute_reply": "2024-06-10T15:53:38.795086Z",
     "shell.execute_reply.started": "2024-06-10T15:53:38.791392Z"
    }
   },
   "outputs": [],
   "source": [
    "def patched_measure_act_multi(self, actions):\n",
    "    feedthrough = self.feedthrough if hasattr(self, 'feedthrough') else False\n",
    "    outputs = []\n",
    "    for action in actions:\n",
    "        if not isinstance(action, torch.Tensor):\n",
    "            action = torch.tensor(action)\n",
    "        if not isinstance(self.state, torch.Tensor):\n",
    "            self.state = torch.tensor(self.state)\n",
    "        \n",
    "        if feedthrough:\n",
    "            y_predict = self.hn(self.state, action)\n",
    "        else:\n",
    "            y_predict = self.hn(self.state)\n",
    "        \n",
    "        outputs.append(y_predict.detach().numpy())\n",
    "    return outputs\n",
    "\n",
    "# Patch the measure_act_multi method in the System class\n",
    "System.measure_act_multi = patched_measure_act_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the model\n",
    "The model is trained using the training data. The model is trained for a specified number of epochs. The loss is calculated using the mean squared error (MSE) loss function. The model is evaluated using the NRMS metric."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eec88b-d17b-4687-8002-55d3c65333c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:53:38.798585Z",
     "iopub.status.busy": "2024-06-10T15:53:38.798405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System_data of length: 7200 nu=(3, 135, 240) ny=None normed=False dt=None\n",
      "System_data_norm: (u0=[[[179.06065963]]\n",
      "\n",
      " [[178.54673909]]\n",
      "\n",
      " [[174.84719291]]], ustd=[[[81.04010374]]\n",
      "\n",
      " [[81.95123325]]\n",
      "\n",
      " [[88.00169806]]], y0=-2.81599406957767, ystd=2.198542996611473)\n",
      "Model already initilized (init_model_done=True), skipping initilizing of the model, the norm and the creation of the optimizer\n",
      "N_training_samples = 7179, batch_size = 32, N_batch_updates_per_epoch = 224\n",
      "Initial Validation sim-NRMS_sys_norm= 0.97310185\n",
      "Starting indefinite training until 10000 seconds have passed due to provided timeout\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60858239e7434f6984c1dd83ebec64fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## New lowest validation loss achieved ########### sim-NRMS_sys_norm = 0.08216279000043869\n",
      "Epoch    1, sqrt loss  0.3984, Val sim-NRMS_sys_norm 0.08216, Time Loss: 12.6%, data: 39.5%, val: 47.8%,  1.2 batches/sec\n",
      "Epoch    2, sqrt loss 0.08218, Val sim-NRMS_sys_norm 0.08755, Time Loss: 11.7%, data: 41.6%, val: 46.7%,  1.2 batches/sec\n",
      "########## New lowest validation loss achieved ########### sim-NRMS_sys_norm = 0.05564379692077637\n",
      "Epoch    3, sqrt loss 0.06614, Val sim-NRMS_sys_norm 0.05564, Time Loss: 11.1%, data: 42.9%, val: 45.9%,  1.2 batches/sec\n",
      "########## New lowest validation loss achieved ########### sim-NRMS_sys_norm = 0.04400921240448952\n",
      "Epoch    4, sqrt loss 0.06055, Val sim-NRMS_sys_norm 0.04401, Time Loss: 10.8%, data: 42.1%, val: 47.0%,  1.2 batches/sec\n",
      "Epoch    5, sqrt loss 0.05664, Val sim-NRMS_sys_norm 0.05439, Time Loss: 10.8%, data: 42.5%, val: 46.7%,  1.2 batches/sec\n",
      "Epoch    6, sqrt loss 0.05145, Val sim-NRMS_sys_norm 0.05865, Time Loss: 10.7%, data: 42.1%, val: 47.2%,  1.2 batches/sec\n",
      "Epoch    7, sqrt loss 0.05112, Val sim-NRMS_sys_norm 0.05053, Time Loss: 10.7%, data: 41.6%, val: 47.7%,  1.2 batches/sec\n",
      "########## New lowest validation loss achieved ########### sim-NRMS_sys_norm = 0.04088861122727394\n",
      "Epoch    8, sqrt loss 0.04599, Val sim-NRMS_sys_norm 0.04089, Time Loss: 10.7%, data: 41.7%, val: 47.6%,  1.2 batches/sec\n",
      "Epoch    9, sqrt loss 0.04841, Val sim-NRMS_sys_norm 0.06396, Time Loss: 10.7%, data: 41.1%, val: 48.2%,  1.2 batches/sec\n",
      "Epoch   10, sqrt loss 0.04843, Val sim-NRMS_sys_norm 0.04661, Time Loss: 10.7%, data: 41.0%, val: 48.3%,  1.2 batches/sec\n",
      "Epoch   11, sqrt loss 0.04694, Val sim-NRMS_sys_norm 0.04798, Time Loss: 10.6%, data: 41.1%, val: 48.3%,  1.2 batches/sec\n",
      "########## New lowest validation loss achieved ########### sim-NRMS_sys_norm = 0.03790387138724327\n",
      "Epoch   12, sqrt loss 0.04429, Val sim-NRMS_sys_norm 0.0379, Time Loss: 10.6%, data: 41.4%, val: 48.1%,  1.2 batches/sec\n",
      "Epoch   13, sqrt loss 0.04266, Val sim-NRMS_sys_norm 0.04194, Time Loss: 10.6%, data: 41.3%, val: 48.2%,  1.2 batches/sec\n",
      "Epoch   14, sqrt loss 0.04989, Val sim-NRMS_sys_norm 0.06222, Time Loss: 10.5%, data: 41.2%, val: 48.3%,  1.2 batches/sec\n",
      "Epoch   15, sqrt loss 0.04577, Val sim-NRMS_sys_norm 0.05053, Time Loss: 10.6%, data: 41.0%, val: 48.5%,  1.2 batches/sec\n",
      "########## New lowest validation loss achieved ########### sim-NRMS_sys_norm = 0.03722080960869789\n",
      "Epoch   16, sqrt loss 0.04292, Val sim-NRMS_sys_norm 0.03722, Time Loss: 10.5%, data: 41.1%, val: 48.4%,  1.2 batches/sec\n",
      "########## New lowest validation loss achieved ########### sim-NRMS_sys_norm = 0.03672950342297554\n",
      "Epoch   17, sqrt loss 0.04361, Val sim-NRMS_sys_norm 0.03673, Time Loss: 10.5%, data: 41.2%, val: 48.3%,  1.2 batches/sec\n",
      "Epoch   18, sqrt loss 0.03953, Val sim-NRMS_sys_norm 0.03714, Time Loss: 10.5%, data: 40.9%, val: 48.6%,  1.2 batches/sec\n",
      "Epoch   19, sqrt loss 0.04153, Val sim-NRMS_sys_norm 0.03908, Time Loss: 10.4%, data: 41.2%, val: 48.4%,  1.2 batches/sec\n"
     ]
    }
   ],
   "source": [
    "def get_base_results(load=True, timeout=10000,n_channels=n_channels, height=height, width=width):\n",
    "    train, val, test = system_data, system_data_val, system_data_test\n",
    "    print(train)\n",
    "    if load:\n",
    "        sys_vbss_s = deepSI.load_system(systemsdir+'sse-cnn-base-force-best')\n",
    "        sys_vbss_s._dt = None\n",
    "        sys_vbss_s.feedthrough=True\n",
    "        sys_vbss_s.norm.u0 = np.mean(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "        sys_vbss_s.norm.ustd = np.std(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "        ##Normalize forces by computing mean and standard deviation over samples\n",
    "        sys_vbss_s.norm.y0 = np.mean(train.y, axis=0)\n",
    "        sys_vbss_s.norm.ystd = np.std(train.y, axis=0)\n",
    "        print(sys_vbss_s.norm)\n",
    "        sys_vbss_best = deepSI.load_system(systemsdir+'sse-cnn-base-force-last')\n",
    "        sys_vbss_best._dt = None\n",
    "        sys_vbss_t = sys_vbss_best.apply_experiment(test).NRMS(test)\n",
    "    else:\n",
    "        \n",
    "        sys_vbss_s = SS_encoder_CNN_video_input(nx=8, na=12, nb=12)\n",
    "        sys_vbss_s.init_model(nu=(3,135,240), ny=1)\n",
    "        sys_vbss_s.feedthrough=True\n",
    "        ##Normalize the frames by computing mean and standard deviation over samples, height, and width\n",
    "        sys_vbss_s.norm.u0 = np.mean(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "        sys_vbss_s.norm.ustd = np.std(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "        ##Normalize forces by computing mean and standard deviation over samples\n",
    "        sys_vbss_s.norm.y0 = np.mean(train.y, axis=0)\n",
    "        sys_vbss_s.norm.ystd = np.std(train.y, axis=0)\n",
    "        print(sys_vbss_s.norm)\n",
    "        ## n_channels, height, width = frames_train.shape[1], frames_train.shape[2], frames_train.shape[3]\n",
    "        sys_vbss_s.fit(system_data, val_sys_data=system_data_val, cuda=True, \n",
    "                       epochs=round(1500/(2*adi)), timeout=timeout, \n",
    "                       batch_size=32, \n",
    "                       validation_measure='sim-NRMS_sys_norm', \n",
    "                       loss_kwargs={'online_construct': True, 'nf':12},\n",
    "                       auto_fit_norm=False,\n",
    "                       #optimizer_kwargs={'lr':5e-4}\n",
    "                      )\n",
    "        sys_vbss_s.save_system('sse-cnn-base-force-best')\n",
    "        sys_vbss_t = sys_vbss_s.apply_experiment(test).NRMS(test)\n",
    "        sys_vbss_s.checkpoint_load_system('_last')\n",
    "        sys_vbss_s.save_system('sse-cnn-base-force-last')\n",
    "    return sys_vbss_s, sys_vbss_t\n",
    "\n",
    "sys_vbss = get_base_results(load=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter search $n_x$\n",
    "The hyperparameter search is performed to find the optimal value of $n_x$. The model is trained for different values of $n_x$ and the NRMS metric is evaluated for each value. The results are plotted to determine the optimal value of $n_x$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb04f5-4892-440d-98aa-294e184f0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sys_vbss\n",
    "def get_repro_systems(nxlist, n_repeat=7, load=True, timeout=600):\n",
    "    train, val, test = system_data, system_data_val, system_data_test\n",
    "    \n",
    "    if load:\n",
    "        return [[deepSI.load_system(systemsdir+f'reprod-enc-{nx}-{i}-last2')  for i in range(n_repeat)] for nx in nxlist]\n",
    "    \n",
    "    for nx in nxlist:\n",
    "        for i in range(n_repeat):\n",
    "            sys_vbss_s = SS_encoder_CNN_video_input(nx=nx, na=12, nb=12)\n",
    "            sys_vbss_s.init_model(nu=(3,135,240), ny=1)\n",
    "            sys_vbss_s.feedthrough=True\n",
    "            ##Normalize the frames by computing mean and standard deviation over samples, height, and width\n",
    "            sys_vbss_s.norm.u0 = np.mean(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "            sys_vbss_s.norm.ustd = np.std(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "            ##Normalize forces by computing mean and standard deviation over samples\n",
    "            sys_vbss_s.norm.y0 = np.mean(train.y, axis=0)\n",
    "            sys_vbss_s.norm.ystd = np.std(train.y, axis=0)\n",
    "            print(sys_vbss_s.norm)\n",
    "            ## n_channels, height, width = frames_train.shape[1], frames_train.shape[2], frames_train.shape[3]\n",
    "            sys_vbss_s.fit(system_data, val_sys_data=system_data_val, cuda=True, \n",
    "                           epochs=round(1500/(2*adi)), timeout=timeout, \n",
    "                           batch_size=64, \n",
    "                           validation_measure='sim-NRMS_sys_norm', \n",
    "                           loss_kwargs={'online_construct': True, 'nf':5},\n",
    "                           auto_fit_norm=False,\n",
    "                           #optimizer_kwargs={'lr':5e-4}\n",
    "                          )        \n",
    "            sys_vbss_s.save_system(f'reprod-enc-{nx}-{i}-best2')\n",
    "            sys_vbss_s.checkpoint_load_system('_last')\n",
    "            sys_vbss_s.save_system(f'reprod-enc-{nx}-{i}-last2')\n",
    "            del sys_vbss_s\n",
    "    return [[deepSI.load_system(systemsdir+f'reprod-enc-{nx}-{i}-last2')  for i in range(n_repeat)] for nx in nxlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b9387a-2959-4b1a-adf7-8fddda067e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outrepo = get_repro_systems([4,5,8,20],n_repeat=3, load=True, timeout=1600)\n",
    "from matplotlib import cm\n",
    "\n",
    "# Adjust the figure height dynamically, reduce the height factor to make figures less tall\n",
    "plt.figure(figsize=(linewidth, 0.8 * len(outrepo)), dpi=dpi)  \n",
    "cmap = cm.get_cmap('tab10')\n",
    "\n",
    "for i, outi in enumerate(outrepo):\n",
    "    col = cmap(i / max(1, len(outrepo) - 1))  # Safeguard division by zero\n",
    "    ax = plt.subplot(len(outrepo), 1, i + 1)  # Adjust subplot index dynamically\n",
    "\n",
    "    # Optionally hide x-axis labels except for the last subplot\n",
    "    if i < len(outrepo) - 1:\n",
    "        ax.xaxis.set_ticklabels([])\n",
    "\n",
    "    for k, outij in enumerate(outi):\n",
    "        plt.semilogy(outij.batch_id, outij.Loss_val, 'o', alpha=0.3, c=col, markersize=0.5,\n",
    "                     label=f'$n_x={outij.nx}$' if k == 0 else None)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlim(-100, 1700)\n",
    "    plt.ylim(0.01, 1)\n",
    "    plt.grid()\n",
    "\n",
    "    if i == len(outrepo) // 2:  # Center label for the middle plot if multiple\n",
    "        plt.ylabel('Test error (NRMS)')\n",
    "\n",
    "plt.xlabel('Optimization time (seconds)')\n",
    "plt.tight_layout(pad=pad)\n",
    "plt.savefig('figures_force/nx-repro.pdf')\n",
    "plt.savefig('figures_force/nx-repro.jpg', dpi=600)\n",
    "plt.show()\n",
    "del outrepo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter search $n_f$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7c24a-e5f7-4267-94c2-1496f5a5856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nf_systems(nflist,base_epochs=20,load=True,last=True):\n",
    "    train, val, test = system_data, system_data_val, system_data_test\n",
    "    \n",
    "    if load:\n",
    "        return [deepSI.load_system(systemsdir+f'enc-nf-{nf}-last') for nf in nflist]\n",
    "    \n",
    "    for nf in nflist:\n",
    "        sys_vbss_s = SS_encoder_CNN_video_input(nx=8, na=12, nb=12)\n",
    "        sys_vbss_s.init_model(nu=(3,135,240), ny=1)\n",
    "        sys_vbss_s.feedthrough=True\n",
    "        ##Normalize the frames by computing mean and standard deviation over samples, height, and width\n",
    "        sys_vbss_s.norm.u0 = np.mean(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "        sys_vbss_s.norm.ustd = np.std(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "        ##Normalize forces by computing mean and standard deviation over samples\n",
    "        sys_vbss_s.norm.y0 = np.mean(train.y, axis=0)\n",
    "        sys_vbss_s.norm.ystd = np.std(train.y, axis=0)\n",
    "        print(sys_vbss_s.norm)\n",
    "        ## n_channels, height, width = frames_train.shape[1], frames_train.shape[2], frames_train.shape[3]\n",
    "        sys_vbss_s.fit(system_data, val_sys_data=system_data_val, cuda=True, \n",
    "                       epochs=base_epochs,  \n",
    "                       batch_size=64, \n",
    "                       validation_measure='sim-NRMS_sys_norm', \n",
    "                       loss_kwargs={'online_construct': True, 'nf':nf},\n",
    "                       auto_fit_norm=False,\n",
    "                       #optimizer_kwargs={'lr':5e-4}\n",
    "                      )    \n",
    "        sys_vbss_s.save_system(f'enc-nf-{nf}-best')\n",
    "        sys_vbss_s.checkpoint_load_system('_last')\n",
    "        sys_vbss_s.save_system(f'enc-nf-{nf}-last')\n",
    "    if last:\n",
    "        return [deepSI.load_system(systemsdir+f'enc-nf-{nf}-last') for nf in nflist]\n",
    "    else:\n",
    "        return [deepSI.load_system(systemsdir+f'enc-nf-{nf}-best') for nf in nflist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d2490-369b-4ec6-a61f-6d9d7f5f4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "nflist = [4,5,7,12,20]\n",
    "outnf = get_nf_systems(nflist,load=True)\n",
    "# torch.save(outnf,'outnf')\n",
    "\n",
    "\n",
    "cmap = cm.get_cmap('viridis')\n",
    "\n",
    "for z,k in enumerate(['time','batch_id']):\n",
    "    plt.figure(figsize=(linewidth,1.5),dpi=dpi)\n",
    "    for (i,outi),nf in zip(enumerate(outnf),nflist):\n",
    "        x = i/(len(outnf)-1)\n",
    "        time = []\n",
    "        loss_val = []\n",
    "        plt.semilogy(outi.__getattribute__(k),outi.Loss_val,c=cmap(x),label='T = '+str(nf))\n",
    "    plt.ylabel('Test Error (NRMS)')\n",
    "    if z==0:\n",
    "        plt.xlabel('Optimization time (seconds)')\n",
    "    else:\n",
    "        plt.xlabel('Batch updates completed')\n",
    "        plt.xlim(0,2500)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid()\n",
    "    plt.tight_layout(pad=pad)\n",
    "    plt.savefig(f'figures_force/nf-influ-{k}.pdf')\n",
    "    plt.show()\n",
    "del outnf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter search $n_a$ and $n_b$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931a537-a5d8-4738-bc67-6099d399da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_na_nb_systems(nalist,load=True,timeout=1200):\n",
    "    train, val, test = system_data, system_data_val, system_data_test\n",
    "    \n",
    "    if load:\n",
    "        return [deepSI.load_system(systemsdir+f'enc-na-{na}-last') for na in nalist]\n",
    "    \n",
    "    for na in nalist:\n",
    "        sys_vbss_s = SS_encoder_CNN_video_input(nx=8, na=na, nb=na)\n",
    "        sys_vbss_s.init_model(nu=(3,135,240), ny=1)\n",
    "        sys_vbss_s.feedthrough=True\n",
    "        ##Normalize the frames by computing mean and standard deviation over samples, height, and width\n",
    "        sys_vbss_s.norm.u0 = np.mean(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "        sys_vbss_s.norm.ustd = np.std(train.u, axis=(0, 2, 3))[:, None, None]\n",
    "        ##Normalize forces by computing mean and standard deviation over samples\n",
    "        sys_vbss_s.norm.y0 = np.mean(train.y, axis=0)\n",
    "        sys_vbss_s.norm.ystd = np.std(train.y, axis=0)\n",
    "        print(sys_vbss_s.norm)\n",
    "        ## n_channels, height, width = frames_train.shape[1], frames_train.shape[2], frames_train.shape[3]\n",
    "        sys_vbss_s.fit(system_data, val_sys_data=system_data_val, cuda=True, \n",
    "                       timeout=timeout, \n",
    "                       batch_size=64, \n",
    "                       validation_measure='sim-NRMS_sys_norm', \n",
    "                       loss_kwargs={'online_construct': True, 'nf':12},\n",
    "                       auto_fit_norm=False,\n",
    "                       #optimizer_kwargs={'lr':5e-4}\n",
    "                      )   \n",
    "        sys_vbss_s.save_system(f'enc-na-{na}-best')\n",
    "        sys_vbss_s.checkpoint_load_system('_last')\n",
    "        sys_vbss_s.save_system(f'enc-na-{na}-last')\n",
    "    return [deepSI.load_system(systemsdir+f'enc-na-{na}-last') for na in nalist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e0b7d-accc-4731-89d0-602f4ff751d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nalist = [6,8,10,12,15,18,20]\n",
    "outna = get_na_nb_systems(nalist,load=True)\n",
    "# torch.save(outna,'outna')\n",
    "\n",
    "from matplotlib import cm\n",
    "plt.figure(figsize=(linewidth,1.5),dpi=dpi)\n",
    "cmap = cm.get_cmap('viridis')\n",
    "# nalist = [1,2,3,4,5,10,20]\n",
    "\n",
    "\n",
    "for (i,outi),na in zip(enumerate(outna),nalist):\n",
    "    x = i/(len(outna)-1)\n",
    "    time = []\n",
    "    loss_val = []\n",
    "    plt.semilogy(outi.time,outi.Loss_val,c=cmap(x),label=f'$n_a = n_b = {str(na)}$',linewidth=1)\n",
    "plt.ylabel('Test error (NRMS)')\n",
    "plt.xlabel('Optimization time (seconds)')\n",
    "plt.legend(loc='upper right',ncol=2)\n",
    "plt.grid()\n",
    "plt.tight_layout(pad=pad)\n",
    "plt.savefig(f'figures_force/nanb-fig.pdf')\n",
    "plt.show()\n",
    "del outna"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model evaluation\n",
    "The model is evaluated using the test data. The NRMS metric is calculated to evaluate the model's performance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84587c-cb31-4d92-a958-a79aaf925a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_vbss_s = deepSI.load_system(os.path.join(systemsdir, \"sse-cnn-base-force-best\"))\n",
    "sys_vbss_s.feedthrough=True\n",
    "##Normalize the frames by computing mean and standard deviation over samples, height, and width\n",
    "sys_vbss_s.norm.u0 = np.mean(system_data.u, axis=(0, 2, 3))[:, None, None]\n",
    "sys_vbss_s.norm.ustd = np.std(system_data.u, axis=(0, 2, 3))[:, None, None]\n",
    "##Normalize forces by computing mean and standard deviation over samples\n",
    "sys_vbss_s.norm.y0 = np.mean(system_data.y, axis=0)\n",
    "sys_vbss_s.norm.ystd = np.std(system_data.y, axis=0)\n",
    "tested_nrms = sys_vbss_s.apply_experiment(system_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e752f0-d23d-41ac-834f-2780a92d2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_data_test_y = system_data_test.y  # Replace with actual data\n",
    "tested_nrms_y = tested_nrms.y  # Replace with actual data\n",
    "\n",
    "# Plot the data\n",
    "plt.plot(system_data_test_y, label='Measured')\n",
    "plt.plot(tested_nrms_y, label='Simulated Force')\n",
    "plt.plot([a - b for a, b in zip(system_data_test_y, tested_nrms_y)], label='Residual')\n",
    "print(sys_vbss_s.apply_experiment(system_data_test).NRMS(system_data_test))\n",
    "# Label axes\n",
    "plt.ylabel('Force (N)')\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "# Adjust x-ticks and labels\n",
    "#x_ticks = range(0, 200, 20)\n",
    "#x_tick_labels = [str(x/20) for x in x_ticks]\n",
    "#plt.xticks(ticks=x_ticks, labels=x_tick_labels)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# Show and save the plot\n",
    "plt.savefig(\"testplots.eps\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
